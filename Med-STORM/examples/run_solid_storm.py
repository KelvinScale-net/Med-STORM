#!/usr/bin/env python3
"""
üöÄ SOLID MED-STORM RUNNER
Runner para testing del nuevo solid engine con OpenRouter + Gemini 2.5 Flash
"""

import asyncio
import argparse
import logging
import os
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from med_storm.core.solid_engine import SolidMedStormEngine, SolidEngineConfig
from med_storm.core.interfaces import PerformanceMode

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config() -> SolidEngineConfig:
    """Load configuration from environment variables"""
    
    # Required keys
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
    if not openrouter_api_key:
        raise ValueError("OPENROUTER_API_KEY environment variable is required")
    
    # Optional keys
    deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
    serper_api_key = os.getenv("SERPER_API_KEY")
    pubmed_email = os.getenv("PUBMED_EMAIL")
    pubmed_api_key = os.getenv("PUBMED_API_KEY")
    
    return SolidEngineConfig(
        openrouter_api_key=openrouter_api_key,
        deepseek_api_key=deepseek_api_key,
        serper_api_key=serper_api_key,
        pubmed_email=pubmed_email,
        pubmed_api_key=pubmed_api_key,
        performance_mode=PerformanceMode.BALANCED,
        max_evidence_sources=15,
        enable_local_corpus=True,
        enable_pubmed=bool(pubmed_email),
        enable_serper=bool(serper_api_key)
    )


async def run_health_check(engine: SolidMedStormEngine):
    """Run comprehensive health check"""
    print("\nüîç HEALTH CHECK")
    print("=" * 50)
    
    health_status = await engine.health_check()
    
    print(f"Engine Status: {'‚úÖ HEALTHY' if health_status['overall_healthy'] else '‚ùå UNHEALTHY'}")
    print(f"LLM Provider: {'‚úÖ HEALTHY' if health_status['llm_provider'] else '‚ùå UNHEALTHY'}")
    
    print("\nConnectors:")
    for name, status in health_status["connectors"].items():
        print(f"  {name}: {'‚úÖ HEALTHY' if status else '‚ùå UNHEALTHY'}")
    
    return health_status["overall_healthy"]


async def run_performance_test(engine: SolidMedStormEngine, topic: str):
    """Run performance test"""
    print(f"\n‚ö° PERFORMANCE TEST: {topic}")
    print("=" * 50)
    
    # Generate report
    report = await engine.generate_medical_report(topic)
    
    # Display results
    print(f"‚úÖ Report generated successfully!")
    print(f"‚è±Ô∏è  Total time: {report.generation_time:.2f} seconds")
    print(f"üìä Quality score: {report.quality_score:.1f}/100")
    print(f"üìö Evidence sources: {len(report.evidence_sources)}")
    
    # Performance breakdown
    metrics = report.performance_metrics
    print(f"\nPerformance Breakdown:")
    print(f"  Evidence retrieval: {metrics.get('evidence_retrieval_time', 0):.2f}s")
    print(f"  Content generation: {metrics.get('content_generation_time', 0):.2f}s")
    
    # LLM provider stats
    llm_stats = metrics.get('llm_provider_stats', {})
    if llm_stats:
        primary_stats = llm_stats.get('primary_provider', {})
        print(f"\nLLM Provider Stats:")
        print(f"  Model: {primary_stats.get('model', 'unknown')}")
        print(f"  Success rate: {primary_stats.get('success_rate', 0):.2%}")
        print(f"  Total requests: {primary_stats.get('total_requests', 0)}")
    
    return report


async def display_report_summary(report):
    """Display report summary"""
    print(f"\nüìã REPORT SUMMARY")
    print("=" * 50)
    
    print(f"Topic: {report.topic}")
    print(f"Quality Score: {report.quality_score:.1f}/100")
    print(f"Evidence Sources: {len(report.evidence_sources)}")
    
    print(f"\nüìù Executive Summary Preview:")
    summary_preview = report.executive_summary[:200] + "..." if len(report.executive_summary) > 200 else report.executive_summary
    print(summary_preview)
    
    print(f"\nüìö Evidence Sources:")
    for i, source in enumerate(report.evidence_sources[:5]):  # Show first 5
        print(f"  {i+1}. {source.title[:60]}... (Confidence: {source.confidence_score:.2f})")
    
    if len(report.evidence_sources) > 5:
        print(f"  ... and {len(report.evidence_sources) - 5} more sources")


async def save_full_report(report, output_dir: str = "output"):
    """Save full report to file"""
    os.makedirs(output_dir, exist_ok=True)
    
    # Generate filename
    safe_topic = "".join(c for c in report.topic if c.isalnum() or c in (' ', '-', '_')).rstrip()
    filename = f"{safe_topic.replace(' ', '_')}_solid_report.md"
    filepath = os.path.join(output_dir, filename)
    
    # Generate full report content
    content = f"""# Medical Research Report: {report.topic}

**Generated by:** Med-STORM Solid Engine  
**Generation Time:** {report.generation_time:.2f} seconds  
**Quality Score:** {report.quality_score:.1f}/100  
**Evidence Sources:** {len(report.evidence_sources)}

---

{report.executive_summary}

---

{report.main_content}

---

{report.clinical_recommendations}

---

## Evidence Sources

"""
    
    for i, source in enumerate(report.evidence_sources):
        content += f"{i+1}. **{source.title}**\n"
        content += f"   - Source: {source.source_type}\n"
        content += f"   - Confidence: {source.confidence_score:.2f}\n"
        content += f"   - URL: {source.url}\n"
        if hasattr(source, 'pmid') and source.pmid:
            content += f"   - PMID: {source.pmid}\n"
        content += "\n"
    
    # Performance metrics
    content += f"""
---

## Performance Metrics

- **Total Generation Time:** {report.generation_time:.2f} seconds
- **Evidence Retrieval Time:** {report.performance_metrics.get('evidence_retrieval_time', 0):.2f} seconds
- **Content Generation Time:** {report.performance_metrics.get('content_generation_time', 0):.2f} seconds
- **Evidence Sources Count:** {report.performance_metrics.get('evidence_sources_count', 0)}

"""
    
    # Write to file
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"\nüíæ Full report saved to: {filepath}")
    return filepath


async def main():
    """Main runner function"""
    parser = argparse.ArgumentParser(description="Solid Med-STORM Runner")
    parser.add_argument("--topic", default="Type 2 Diabetes Treatment", help="Medical topic to research")
    parser.add_argument("--health-check", action="store_true", help="Run health check only")
    parser.add_argument("--output-dir", default="output", help="Output directory for reports")
    parser.add_argument("--performance-mode", choices=["fast", "balanced", "quality"], default="balanced", help="Performance mode")
    
    args = parser.parse_args()
    
    try:
        print("üöÄ SOLID MED-STORM ENGINE")
        print("=" * 50)
        print("Provider: OpenRouter (Gemini 2.5 Flash)")
        print("Connectors: PubMed + Serper + Local Corpus")
        print("Mode: Solid Architecture with Standard Interfaces")
        
        # Load configuration
        print("\nüìã Loading configuration...")
        config = load_config()
        
        # Set performance mode
        if args.performance_mode == "fast":
            config.performance_mode = PerformanceMode.ULTRA_FAST
        elif args.performance_mode == "quality":
            config.performance_mode = PerformanceMode.GOLD_STANDARD
        else:
            config.performance_mode = PerformanceMode.BALANCED
        
        print(f"Performance Mode: {config.performance_mode.value}")
        print(f"Max Evidence Sources: {config.max_evidence_sources}")
        print(f"Enabled Connectors: PubMed={config.enable_pubmed}, Serper={config.enable_serper}, Local={config.enable_local_corpus}")
        
        # Initialize engine
        print("\nüèóÔ∏è Initializing Solid Engine...")
        engine = SolidMedStormEngine(config)
        
        # Health check
        is_healthy = await run_health_check(engine)
        
        if args.health_check:
            print(f"\n{'‚úÖ SYSTEM HEALTHY' if is_healthy else '‚ùå SYSTEM UNHEALTHY'}")
            return
        
        if not is_healthy:
            print("\n‚ö†Ô∏è WARNING: Some components are unhealthy. Proceeding anyway...")
        
        # Performance test
        report = await run_performance_test(engine, args.topic)
        
        # Display summary
        await display_report_summary(report)
        
        # Save full report
        await save_full_report(report, args.output_dir)
        
        # Final stats
        engine_stats = engine.get_performance_stats()
        print(f"\nüìä FINAL STATS")
        print("=" * 50)
        print(f"Success Rate: {engine_stats['success_rate']:.2%}")
        print(f"Average Response Time: {engine_stats['average_response_time']:.2f}s")
        print(f"Total Requests: {engine_stats['total_requests']}")
        
        print(f"\nüéâ SOLID MED-STORM ENGINE TEST COMPLETED SUCCESSFULLY!")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Test interrupted by user")
    except Exception as e:
        logger.error(f"Test failed: {e}")
        print(f"\n‚ùå TEST FAILED: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main()) 